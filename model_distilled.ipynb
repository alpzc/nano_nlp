{"cells":[{"cell_type":"code","execution_count":null,"id":"settled-gossip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"settled-gossip","executionInfo":{"status":"ok","timestamp":1699370414506,"user_tz":360,"elapsed":8349,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"e7c231de-b1ae-4ee8-e94d-a758b35f1a38"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.1.0+cu118\n","Collecting traitlets==4.3.3\n","  Using cached traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n","Collecting ipython-genutils (from traitlets==4.3.3)\n","  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n","Collecting six (from traitlets==4.3.3)\n","  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting decorator (from traitlets==4.3.3)\n","  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n","Installing collected packages: ipython-genutils, six, decorator, traitlets\n","  Attempting uninstall: ipython-genutils\n","    Found existing installation: ipython-genutils 0.2.0\n","    Uninstalling ipython-genutils-0.2.0:\n","      Successfully uninstalled ipython-genutils-0.2.0\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","  Attempting uninstall: decorator\n","    Found existing installation: decorator 5.1.1\n","    Uninstalling decorator-5.1.1:\n","      Successfully uninstalled decorator-5.1.1\n","  Attempting uninstall: traitlets\n","    Found existing installation: traitlets 4.3.3\n","    Uninstalling traitlets-4.3.3:\n","      Successfully uninstalled traitlets-4.3.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","jupyter-core 5.4.0 requires traitlets>=5.3, but you have traitlets 4.3.3 which is incompatible.\n","jupyter-server 1.24.0 requires traitlets>=5.1, but you have traitlets 4.3.3 which is incompatible.\n","moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n","nbclient 0.8.0 requires traitlets>=5.4, but you have traitlets 4.3.3 which is incompatible.\n","nbconvert 6.5.4 requires traitlets>=5.0, but you have traitlets 4.3.3 which is incompatible.\n","nbformat 5.9.2 requires traitlets>=5.1, but you have traitlets 4.3.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed decorator-5.1.1 ipython-genutils-0.2.0 six-1.16.0 traitlets-4.3.3\n","\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==228 (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==228\u001b[0m\u001b[31m\n","\u001b[0mTrue\n"]}],"source":["import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(torch.__version__)\n","\n","\n","!python -m pip install traitlets==4.3.3 --force-reinstall\n","!pip install pywin32==228\n","\n","print(torch.cuda.is_available())\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4usoLZeuXM50","executionInfo":{"status":"ok","timestamp":1699370415632,"user_tz":360,"elapsed":1131,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"0c7e42d4-adce-4443-880b-8644a8c7ac63"},"id":"4usoLZeuXM50","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","id":"technological-mercy","metadata":{"id":"technological-mercy"},"source":["## Importing Training Text (can be changed later on)"]},{"cell_type":"code","execution_count":null,"id":"political-google","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"political-google","executionInfo":{"status":"ok","timestamp":1699370415632,"user_tz":360,"elapsed":10,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"84f414c8-24d8-4f93-c6b4-ad59e7cd4c63"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'sed by many more; for if you succeed in this you will have achieved no small success.” In profound silence I listened to what my friend said, and his observations made such an impression on me that, without attempting to question them, I admitted their soundness, and out of them I determined to make this Preface; wherein, gentle reader, thou wilt perceive my friend’s good sense, my good fortune in finding such an adviser in such a time of need, and what thou hast gained in receiving, without addition or alteration, the story of the famous Don Quixote of La Mancha, who is held by all the inhabitants of the district of the Campo de Montiel to have been the chastest lover and the bravest knight that has for many years been seen in that neighbourhood. I have no desire to magnify the service I render thee in making thee acquainted with so renowned and honoured a knight, but I do desire thy thanks for the acquaintance thou wilt make with the famous Sancho Panza, his squire, in whom, to my th'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["with open('/content/drive/MyDrive/LLM TESTING/NanoGPT/data/don_quixote.txt', \"r\", encoding = 'utf-8') as f:\n","    text = f.read()\n","\n","text= text.replace('\\n', ' ').replace('  ', ' ')[121506:]\n","text[:1000]"]},{"cell_type":"code","execution_count":null,"id":"ordinary-rates","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ordinary-rates","executionInfo":{"status":"ok","timestamp":1699370415632,"user_tz":360,"elapsed":9,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"199cc540-d69c-45b7-c2ef-e2579860acb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Words on .txt file:  2190617\n","Unique characters:  100\n"," !$%&()*,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyzÁÆÑÚàáæéëíñóùŒœ—‘’“”•™\n","\n"]}],"source":["print('Words on .txt file: ', len(text))\n","\n","chars = sorted(list(set(text)))\n","char_vocab_size = len(chars)\n","\n","print('Unique characters: ', char_vocab_size)\n","print(''.join(chars))\n","print()"]},{"cell_type":"code","execution_count":null,"id":"premium-voltage","metadata":{"id":"premium-voltage"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"angry-conditioning","metadata":{"id":"angry-conditioning"},"source":["## Using TikToken For Tokenization (can be changed later on to other like SentencePiece)\n","Tiktoken does tokenization per word and special character."]},{"cell_type":"code","execution_count":null,"id":"discrete-brass","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"discrete-brass","executionInfo":{"status":"ok","timestamp":1699370424506,"user_tz":360,"elapsed":8880,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"07daec4e-0638-4eb7-ccee-29a2afa92ef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tiktoken\n","  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n","Installing collected packages: tiktoken\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tiktoken-0.5.1\n"]}],"source":["!pip install tiktoken"]},{"cell_type":"code","execution_count":null,"id":"collect-yacht","metadata":{"id":"collect-yacht"},"outputs":[],"source":["import tiktoken\n","enc = tiktoken.get_encoding('gpt2')"]},{"cell_type":"code","execution_count":null,"id":"cross-taylor","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cross-taylor","executionInfo":{"status":"ok","timestamp":1699370426527,"user_tz":360,"elapsed":8,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"e38c43c5-6ee9-4b0d-9e74-e850f9e93b37"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tonkenized 'testing':  [33407]\n","testing\n"]}],"source":["#Testing encoder\n","encoded_test_str= enc.encode('testing')\n","print(\"Tonkenized 'testing': \", encoded_test_str)\n","\n","decoded_test_str= enc.decode(encoded_test_str)\n","print(decoded_test_str)"]},{"cell_type":"markdown","id":"alien-chance","metadata":{"id":"alien-chance"},"source":["## Preparing Training Data"]},{"cell_type":"code","execution_count":null,"id":"cultural-oracle","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cultural-oracle","executionInfo":{"status":"ok","timestamp":1699370426992,"user_tz":360,"elapsed":471,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"e19afc31-408e-479a-f60d-dd57d5b926c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded text:  [36622, 416, 867, 517, 26, 329, 611, 345, 6758, 287, 428, 345, 481, 423, 8793, 645, 1402, 1943, 13, 447, 251, 554, 11982, 9550, 314, 16399, 284, 644, 616, 1545, 531, 11, 290, 465, 13050, 925, 884, 281, 10647, 319, 502, 326, 11, 1231, 9361, 284, 1808, 606, 11, 314, 6848, 511, 2128, 1108, 11, 290, 503, 286, 606, 314, 5295, 284, 787, 428, 3771, 2550, 26, 22881, 11, 10296, 9173, 11, 14210, 266, 2326, 19973, 616, 1545, 447, 247, 82, 922, 2565, 11, 616, 922, 15807, 287, 4917, 884, 281, 12534, 287, 884, 257, 640, 286, 761, 11, 290]\n","Decoded text:  sed by many more; for if you succeed in this you will have achieved no small success.” In profound silence I listened to what my friend said, and his observations made such an impression on me that, without attempting to question them, I admitted their soundness, and out of them I determined to make this Preface; wherein, gentle reader, thou wilt perceive my friend’s good sense, my good fortune in finding such an adviser in such a time of need, and\n","torch.Size([541159])\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","encoded_text = enc.encode(text)\n","data = torch.tensor(encoded_text, dtype=torch.long)\n","\n","print('Encoded text: ', encoded_text[:100])\n","print('Decoded text: ', enc.decode(encoded_text[:100]))\n","print(data.shape)"]},{"cell_type":"code","execution_count":null,"id":"interim-cheese","metadata":{"id":"interim-cheese"},"outputs":[],"source":["# Setting the training split to 90%\n","train_split = int(0.9 * len(data))\n","train_data = data[:train_split]\n","val_data = data[train_split:]"]},{"cell_type":"code","execution_count":null,"id":"blessed-frederick","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"blessed-frederick","executionInfo":{"status":"ok","timestamp":1699370427166,"user_tz":360,"elapsed":176,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"4761f3ba-1486-4cb6-f3ee-e8def6b1549d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Context:  tensor([36622]) Target:  tensor(416)\n","Context:  tensor([36622,   416]) Target:  tensor(867)\n","Context:  tensor([36622,   416,   867]) Target:  tensor(517)\n","Context:  tensor([36622,   416,   867,   517]) Target:  tensor(26)\n","Context:  tensor([36622,   416,   867,   517,    26]) Target:  tensor(329)\n","Context:  tensor([36622,   416,   867,   517,    26,   329]) Target:  tensor(611)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611]) Target:  tensor(345)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345]) Target:  tensor(6758)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758]) Target:  tensor(287)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287]) Target:  tensor(428)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428]) Target:  tensor(345)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345]) Target:  tensor(481)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481]) Target:  tensor(423)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423]) Target:  tensor(8793)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793]) Target:  tensor(645)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645]) Target:  tensor(1402)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402]) Target:  tensor(1943)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943]) Target:  tensor(13)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13]) Target:  tensor(447)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447]) Target:  tensor(251)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251]) Target:  tensor(554)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554]) Target:  tensor(11982)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982]) Target:  tensor(9550)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550]) Target:  tensor(314)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314]) Target:  tensor(16399)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399]) Target:  tensor(284)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284]) Target:  tensor(644)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644]) Target:  tensor(616)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616]) Target:  tensor(1545)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545]) Target:  tensor(531)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11]) Target:  tensor(290)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290]) Target:  tensor(465)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465]) Target:  tensor(13050)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050]) Target:  tensor(925)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925]) Target:  tensor(884)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884]) Target:  tensor(281)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281]) Target:  tensor(10647)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647]) Target:  tensor(319)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319]) Target:  tensor(502)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502]) Target:  tensor(326)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11]) Target:  tensor(1231)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231]) Target:  tensor(9361)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361]) Target:  tensor(284)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284]) Target:  tensor(1808)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808]) Target:  tensor(606)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11]) Target:  tensor(314)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314]) Target:  tensor(6848)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848]) Target:  tensor(511)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511]) Target:  tensor(2128)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128]) Target:  tensor(1108)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11]) Target:  tensor(290)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290]) Target:  tensor(503)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503]) Target:  tensor(286)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286]) Target:  tensor(606)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606]) Target:  tensor(314)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314]) Target:  tensor(5295)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295]) Target:  tensor(284)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284]) Target:  tensor(787)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787]) Target:  tensor(428)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428]) Target:  tensor(3771)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771]) Target:  tensor(2550)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550]) Target:  tensor(26)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26]) Target:  tensor(22881)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11]) Target:  tensor(10296)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296]) Target:  tensor(9173)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11]) Target:  tensor(14210)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210]) Target:  tensor(266)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266]) Target:  tensor(2326)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326]) Target:  tensor(19973)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973]) Target:  tensor(616)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616]) Target:  tensor(1545)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545]) Target:  tensor(447)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447]) Target:  tensor(247)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247]) Target:  tensor(82)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82]) Target:  tensor(922)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922]) Target:  tensor(2565)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11]) Target:  tensor(616)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616]) Target:  tensor(922)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922]) Target:  tensor(15807)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807]) Target:  tensor(287)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287]) Target:  tensor(4917)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917]) Target:  tensor(884)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884]) Target:  tensor(281)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281]) Target:  tensor(12534)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534]) Target:  tensor(287)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287]) Target:  tensor(884)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884]) Target:  tensor(257)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257]) Target:  tensor(640)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640]) Target:  tensor(286)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286]) Target:  tensor(761)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11]) Target:  tensor(290)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290]) Target:  tensor(644)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644]) Target:  tensor(14210)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210]) Target:  tensor(19338)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338]) Target:  tensor(8618)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618]) Target:  tensor(287)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287]) Target:  tensor(6464)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11]) Target:  tensor(1231)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231]) Target:  tensor(3090)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090]) Target:  tensor(393)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393]) Target:  tensor(35635)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11]) Target:  tensor(262)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262]) Target:  tensor(1621)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621]) Target:  tensor(286)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286]) Target:  tensor(262)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262]) Target:  tensor(5863)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863]) Target:  tensor(2094)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094]) Target:  tensor(2264)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264]) Target:  tensor(844)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844]) Target:  tensor(1258)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258]) Target:  tensor(286)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258,   286]) Target:  tensor(4689)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258,   286,  4689]) Target:  tensor(1869)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258,   286,  4689,  1869]) Target:  tensor(11693)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258,   286,  4689,  1869, 11693]) Target:  tensor(11)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258,   286,  4689,  1869, 11693,    11]) Target:  tensor(508)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258,   286,  4689,  1869, 11693,    11,   508]) Target:  tensor(318)\n","Context:  tensor([36622,   416,   867,   517,    26,   329,   611,   345,  6758,   287,\n","          428,   345,   481,   423,  8793,   645,  1402,  1943,    13,   447,\n","          251,   554, 11982,  9550,   314, 16399,   284,   644,   616,  1545,\n","          531,    11,   290,   465, 13050,   925,   884,   281, 10647,   319,\n","          502,   326,    11,  1231,  9361,   284,  1808,   606,    11,   314,\n","         6848,   511,  2128,  1108,    11,   290,   503,   286,   606,   314,\n","         5295,   284,   787,   428,  3771,  2550,    26, 22881,    11, 10296,\n","         9173,    11, 14210,   266,  2326, 19973,   616,  1545,   447,   247,\n","           82,   922,  2565,    11,   616,   922, 15807,   287,  4917,   884,\n","          281, 12534,   287,   884,   257,   640,   286,   761,    11,   290,\n","          644, 14210, 19338,  8618,   287,  6464,    11,  1231,  3090,   393,\n","        35635,    11,   262,  1621,   286,   262,  5863,  2094,  2264,   844,\n","         1258,   286,  4689,  1869, 11693,    11,   508,   318]) Target:  tensor(2714)\n"]}],"source":["block_size = 128\n","x, y = train_data[0: block_size], train_data[1: block_size + 1]\n","\n","for i in range(block_size):\n","    context= x[:i+1]\n","    target= y[i]\n","    print('Context: ', context, 'Target: ', target)"]},{"cell_type":"code","execution_count":null,"id":"honest-position","metadata":{"id":"honest-position"},"outputs":[],"source":["def get_batch(data, seq_len, i):\n","    \"\"\"Get a batch of data\n","    Parameters\n","    ----------\n","    data : torch.tensor\n","        The data to get the batch from\n","    seq_len : int\n","        The length of the sequence\n","    i : int\n","        The batch index\n","    Returns\n","    -------\n","    torch.tensor\n","        The input sequence\n","    torch.tensor\n","        The target sequence\n","    \"\"\"\n","    seq_len = min(seq_len, len(data) - 1 - i)\n","    inputs = data[i: i + seq_len]\n","    targets = data[i + 1: i + 1 + seq_len].reshape(-1)\n","    return inputs, targets\n","\n","def get_random_batch(split_type='train', block_size=8, batch_size = 4):\n","    \"\"\"Get a random batch of data\n","    Parameters\n","    ----------\n","    split_type : str, optional\n","        The split to get the batch from, by default 'train'\n","    block_size : int, optional\n","        The size of the block (quantity of words per example in the batch), by default 8\n","    batch_size : int, optional\n","        The batch size (quantity of examples in the batch), by default 4\n","    Returns\n","    -------\n","    torch.tensor\n","        The input sequence of size (batch_size, block_size)\n","    torch.tensor\n","        The target sequence of size (batch_size, block_size)\n","    \"\"\"\n","    data = train_data if split_type == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","\n","    x, y = x.to(device), y.to(device)\n","\n","    return x, y\n","\n"]},{"cell_type":"code","execution_count":null,"id":"still-chicken","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"still-chicken","executionInfo":{"status":"ok","timestamp":1699370434485,"user_tz":360,"elapsed":7160,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"e0ffa55a-57ed-40f6-bd21-5c02647083ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Batch input x:  ’s the story, and,\n","Size of complete X Batch:  torch.Size([4, 8])\n","Batch target y:  �s the story, and, tro\n","Size of complete Y Batch:  torch.Size([4, 8])\n"]}],"source":["test_batch_x, test_batch_y= get_random_batch(split_type='train')\n","#printing the decoded batches\n","print('Batch input x: ', enc.decode(test_batch_x[0].tolist()))\n","print('Size of complete X Batch: ', test_batch_x.shape)\n","print('Batch target y: ', enc.decode(test_batch_y[0].tolist()))\n","print('Size of complete Y Batch: ', test_batch_y.shape)\n","\n","vocab_size = len(encoded_text)"]},{"cell_type":"markdown","id":"catholic-chinese","metadata":{"id":"catholic-chinese"},"source":["## Implementing Word2Vec Embeddings (can be changed later on like GloVe)\n","In this case, the embedding imported transforms each word and special character into a 300-dim vector, meaning that a sentence of 8 words will be transformed into a [8, 300] tensor."]},{"cell_type":"code","execution_count":null,"id":"respective-indication","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":532},"id":"respective-indication","executionInfo":{"status":"ok","timestamp":1699370454725,"user_tz":360,"elapsed":20252,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"b2874e24-b1bc-46a5-c9cf-33628e30b563"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","Collecting numpy==1.21.6\n","  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","jax 0.4.16 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n","jaxlib 0.4.16+cuda11.cudnn86 requires numpy>=1.22, but you have numpy 1.21.6 which is incompatible.\n","moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n","plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n","tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.21.6\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["#installing past numpy version\n","!pip install gensim\n","!pip install numpy==1.21.6"]},{"cell_type":"code","execution_count":null,"id":"mature-control","metadata":{"id":"mature-control"},"outputs":[],"source":["#implementing word embedding using Word2Vec\n","from gensim.models import Word2Vec\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.manifold import TSNE\n","from gensim.models import KeyedVectors\n","\n","#loading model in './embedding_models/GoogleNews-vectors-negative300.bin'\n","model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/LLM TESTING/NanoGPT/embedding_models/GoogleNews-vectors-negative300.bin', binary=True)"]},{"cell_type":"code","execution_count":null,"id":"sonic-primary","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sonic-primary","executionInfo":{"status":"ok","timestamp":1699370519743,"user_tz":360,"elapsed":2198,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"80df84b9-968f-4870-c803-8d3baf5a0501"},"outputs":[{"output_type":"stream","name":"stdout","text":["(298727, 300)\n","Unique words (vocab size):  31700\n"]}],"source":["#using the model to get embeddings of our text\n","embeddings = []\n","for word in text.split(' '):\n","    try:\n","        embeddings.append(model[word])\n","    except:\n","        pass\n","\n","embeddings = np.array(embeddings)\n","print(embeddings.shape)\n","\n","words_vocab_size = len(list(set( text.split(' '))))\n","print(\"Unique words (vocab size): \", words_vocab_size)"]},{"cell_type":"code","execution_count":null,"id":"statewide-period","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"statewide-period","executionInfo":{"status":"ok","timestamp":1699370519744,"user_tz":360,"elapsed":7,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"5812d288-fcf5-400f-cbd7-47f69bbbb52c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word:  by\n","Embedding:  [-1.15722656e-01 -3.14941406e-02  1.59179688e-01  1.38671875e-01\n"," -5.06591797e-03  2.81982422e-02 -3.39355469e-02 -1.15722656e-01\n","  3.24707031e-02  1.38671875e-01 -1.00097656e-01 -1.26953125e-01\n"," -3.95507812e-02 -1.83105469e-02  2.34603882e-04 -8.05664062e-02\n","  4.51660156e-02  9.81445312e-02 -5.66406250e-02  6.00585938e-02\n","  8.88671875e-02  5.02929688e-02 -1.64794922e-02 -5.56640625e-02\n","  2.13867188e-01  1.42822266e-02 -1.31835938e-01  3.19824219e-02\n","  3.11279297e-02  1.25976562e-01 -3.47900391e-03 -1.55273438e-01\n"," -1.68945312e-01  1.40625000e-01  1.60156250e-01 -3.75976562e-02\n"," -9.47265625e-02 -3.90625000e-02  1.70898438e-01 -5.12695312e-02\n","  1.46484375e-01  9.61914062e-02 -2.66113281e-02  3.90625000e-02\n","  1.35742188e-01  5.27343750e-02 -4.15039062e-02 -5.20019531e-02\n","  1.57226562e-01  9.37500000e-02  5.67626953e-03  1.26953125e-01\n"," -5.31005859e-03 -4.80957031e-02  5.41992188e-02  1.66992188e-01\n","  3.85742188e-02  3.46679688e-02 -9.81445312e-02 -7.47070312e-02\n"," -1.33789062e-01  2.69775391e-02 -1.04003906e-01 -2.49023438e-02\n"," -7.71484375e-02 -2.36816406e-02 -1.22070312e-03  1.06445312e-01\n","  4.37011719e-02  1.96289062e-01 -2.20947266e-02 -7.95898438e-02\n","  2.49023438e-02  3.88183594e-02 -1.08032227e-02  2.26562500e-01\n","  8.69140625e-02  1.70898438e-01  5.07812500e-02  7.71484375e-02\n"," -1.30462646e-03  6.43920898e-03  4.17480469e-02  2.52685547e-02\n","  9.17968750e-02 -8.00781250e-02 -6.73828125e-02  4.00390625e-02\n"," -3.51562500e-02 -7.03125000e-02 -9.47265625e-02  1.81640625e-01\n"," -7.56835938e-02 -5.71289062e-02  2.87109375e-01  1.14257812e-01\n"," -1.46484375e-01 -1.61132812e-02 -5.70678711e-03 -4.32128906e-02\n","  2.18750000e-01 -1.07910156e-01 -5.15136719e-02  9.57031250e-02\n"," -4.02832031e-02  1.15722656e-01 -7.66601562e-02  4.78515625e-02\n","  2.80761719e-02 -1.04003906e-01  6.44531250e-02  4.85839844e-02\n"," -7.12890625e-02  3.27148438e-02 -6.73828125e-02 -8.15429688e-02\n","  4.37011719e-02  1.09863281e-03  1.70898438e-01  1.98242188e-01\n"," -1.23046875e-01  1.75781250e-01 -1.85546875e-01 -7.93457031e-03\n","  6.17675781e-02  3.34472656e-02  5.71289062e-02 -2.19726562e-03\n","  1.99218750e-01  6.54296875e-02 -2.82287598e-03  9.86328125e-02\n","  3.89099121e-03 -8.78906250e-02 -7.51953125e-02  2.52685547e-02\n"," -6.12792969e-02 -5.51757812e-02 -1.26953125e-01 -6.01196289e-03\n","  1.37695312e-01 -3.34472656e-02 -7.37304688e-02  7.81250000e-02\n","  4.17480469e-02 -5.93261719e-02  5.88378906e-02  9.26971436e-04\n","  8.64257812e-02  9.17968750e-02  5.39550781e-02  4.15039062e-02\n","  1.36718750e-01  1.89453125e-01  8.44726562e-02 -1.46484375e-01\n"," -5.88378906e-02 -1.66015625e-01  3.34472656e-02  5.21850586e-03\n"," -9.88769531e-03  8.30078125e-02  4.95605469e-02  1.06445312e-01\n"," -1.23046875e-01 -1.14135742e-02  1.07421875e-02 -7.47070312e-02\n"," -3.14941406e-02  1.23901367e-02 -1.46484375e-01 -2.07031250e-01\n"," -6.88476562e-02 -1.57226562e-01 -1.94335938e-01 -8.78906250e-02\n"," -4.54101562e-02  8.54492188e-02 -5.56640625e-02 -8.34960938e-02\n"," -5.12695312e-02 -1.64062500e-01 -1.17187500e-01  1.12792969e-01\n"," -6.05468750e-02  1.78222656e-02 -3.41796875e-02  1.05957031e-01\n","  8.39843750e-02  5.17578125e-02  6.05468750e-02  1.27563477e-02\n"," -1.01318359e-02  2.94189453e-02 -8.05664062e-02 -9.76562500e-02\n"," -4.79125977e-03  1.53198242e-02 -2.16064453e-02 -3.29589844e-02\n","  1.25000000e-01 -3.51562500e-02 -7.86132812e-02 -1.56250000e-02\n"," -1.20849609e-02  1.60156250e-01  6.64062500e-02  5.95703125e-02\n","  8.34960938e-02 -8.69140625e-02 -5.44433594e-02 -1.64062500e-01\n","  9.71679688e-02  1.01562500e-01  9.58251953e-03  2.35595703e-02\n","  8.39843750e-02 -4.19921875e-02 -4.07714844e-02  4.83398438e-02\n"," -2.46582031e-02 -6.78710938e-02  6.10351562e-02 -1.76757812e-01\n","  3.51562500e-02  4.71191406e-02  2.74658203e-02  1.40625000e-01\n","  2.67578125e-01 -5.12695312e-02  9.42382812e-02 -5.22460938e-02\n","  3.12500000e-02  3.36914062e-02 -8.74023438e-02 -9.08203125e-02\n","  1.03759766e-02  1.11328125e-01 -8.78906250e-02  1.01318359e-02\n"," -1.83593750e-01 -6.25000000e-02  2.01171875e-01 -8.91113281e-03\n","  2.39257812e-02  1.30859375e-01  3.12500000e-01  9.17968750e-02\n"," -1.04492188e-01  2.20947266e-02  5.83496094e-02 -1.44531250e-01\n"," -1.04492188e-01  9.81445312e-02  7.22656250e-02 -1.80664062e-01\n","  1.15722656e-01 -2.90527344e-02  8.64257812e-02 -9.08203125e-02\n","  7.51953125e-02  6.73828125e-02  1.55639648e-02  1.12792969e-01\n"," -1.20239258e-02  1.28906250e-01 -1.57470703e-02  1.38671875e-01\n","  1.73828125e-01  6.34765625e-03  7.37304688e-02  6.68945312e-02\n"," -1.19140625e-01  9.13085938e-02  1.74560547e-02 -8.88671875e-02\n"," -5.51757812e-02 -1.18652344e-01  1.23046875e-01  5.61523438e-03\n","  3.41796875e-02  1.45507812e-01 -5.83496094e-02 -4.19921875e-02\n","  1.57226562e-01  6.93359375e-02 -1.42578125e-01 -3.93066406e-02\n","  8.15429688e-02  6.03027344e-02 -1.21582031e-01 -7.47070312e-02\n"," -6.93359375e-02  3.51562500e-02 -3.22265625e-02  4.76074219e-02\n"," -2.12890625e-01  2.62451172e-02 -6.25000000e-02 -4.15039062e-02]\n"]}],"source":["#printing an example of the embedding\n","print('Word: ', text.split(' ')[1])\n","print('Embedding: ', embeddings[1])"]},{"cell_type":"code","execution_count":null,"id":"cooked-semiconductor","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":909},"id":"cooked-semiconductor","executionInfo":{"status":"ok","timestamp":1699370550714,"user_tz":360,"elapsed":30975,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"d83821f1-9b6f-42cf-8b23-7007ce3d3c56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reducing dimensionality...\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7d7d3358eb00>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 847, in match_library_callback\n","    self._make_controller_from_path(filepath)\n","  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 984, in _make_controller_from_path\n","    lib_controller = controller_class(filepath=filepath, prefix=prefix)\n","  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 111, in __init__\n","    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n","  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n","    self._handle = _dlopen(self._name, mode)\n","OSError: /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so: cannot open shared object file: No such file or directory\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["#using TSNE to reduce the dimensionality of the embeddings for just some words\n","print('Reducing dimensionality...')\n","tsne = TSNE(n_components=2)\n","embeddings_2d = tsne.fit_transform(embeddings[:2500])\n","print('Done!')\n","\n","#plotting the embeddings using matplotlib\n","plt.figure(figsize=(10, 10))\n","plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=1)\n","plt.show()"]},{"cell_type":"markdown","id":"federal-sociology","metadata":{"id":"federal-sociology"},"source":["## Making a Basic Bigram Model\n","Bigram models are the simplest form of language models that assigns probabilities to word sequences. It is based on the assumption that the probability of a word depends only on the previous word. In other words, it assumes that the probability of a word depends only on the previous word. The probability of a word depends on the previous two words in the case of a trigram model. The probability of a word depends on the previous n words in the case of an n-gram model.\n","\n","This simple model is just a random model that generates the next character based on the last character (not even the last n-characters). *Tokens DO NOT talk to each other*."]},{"cell_type":"code","execution_count":null,"id":"bright-privacy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bright-privacy","executionInfo":{"status":"ok","timestamp":1699370550714,"user_tz":360,"elapsed":6,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"7337a6b4-dfb1-49eb-8359-3d246965519c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[71, 56, 70, 71, 60, 65, 58]\n","testing\n"]}],"source":["# For now, we will be using a basic encoding using only individual characters\n","\n","stoi = { ch:i for i,ch in enumerate(chars) }\n","itos = { i:ch for i,ch in enumerate(chars) }\n","encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n","decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n","\n","print(encode(\"testing\"))\n","print(decode(encode(\"testing\")))"]},{"cell_type":"code","execution_count":null,"id":"described-airplane","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"described-airplane","executionInfo":{"status":"ok","timestamp":1699370551090,"user_tz":360,"elapsed":380,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"91e78f40-f9d9-4223-c6b3-54ac0e35a8b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2190617]) torch.int64\n","tensor([70, 56, 55,  0, 53, 76,  0, 64, 52, 65, 76,  0, 64, 66, 69, 56, 23,  0,\n","        57, 66, 69,  0, 60, 57,  0, 76, 66, 72,  0, 70, 72, 54, 54, 56, 56, 55,\n","         0, 60, 65,  0, 71, 59, 60, 70,  0, 76, 66, 72,  0, 74, 60, 63, 63,  0,\n","        59, 52, 73, 56,  0, 52, 54, 59, 60, 56, 73, 56, 55,  0, 65, 66,  0, 70,\n","        64, 52, 63, 63,  0, 70, 72, 54, 54, 56, 70, 70, 10, 97,  0, 33, 65,  0,\n","        67, 69, 66, 57, 66, 72, 65, 55,  0, 70, 60, 63, 56, 65, 54, 56,  0, 33,\n","         0, 63, 60, 70, 71, 56, 65, 56, 55,  0, 71, 66,  0, 74, 59, 52, 71,  0,\n","        64, 76,  0, 57, 69, 60, 56, 65, 55,  0, 70, 52, 60, 55,  8,  0, 52, 65,\n","        55,  0, 59, 60, 70,  0, 66, 53, 70, 56, 69, 73, 52, 71, 60, 66, 65, 70,\n","         0, 64, 52, 55, 56,  0, 70, 72, 54, 59,  0, 52, 65,  0, 60, 64, 67, 69,\n","        56, 70, 70, 60, 66, 65,  0, 66, 65,  0, 64, 56,  0, 71, 59, 52, 71,  8,\n","         0, 74, 60, 71, 59, 66, 72, 71,  0, 52, 71, 71, 56, 64, 67, 71, 60, 65,\n","        58,  0, 71, 66,  0, 68, 72, 56, 70, 71, 60, 66, 65,  0, 71, 59, 56, 64,\n","         8,  0, 33,  0, 52, 55, 64, 60, 71, 71, 56, 55,  0, 71, 59, 56, 60, 69,\n","         0, 70, 66, 72, 65, 55, 65, 56, 70, 70,  8,  0, 52, 65, 55,  0, 66, 72,\n","        71,  0, 66, 57,  0, 71, 59, 56, 64,  0, 33,  0, 55, 56, 71, 56, 69, 64,\n","        60, 65, 56, 55,  0, 71, 66,  0, 64, 52, 62, 56,  0, 71, 59, 60, 70,  0,\n","        40, 69, 56, 57, 52, 54, 56, 23,  0, 74, 59, 56, 69, 56, 60, 65,  8,  0,\n","        58, 56, 65, 71, 63, 56,  0, 69, 56, 52, 55, 56, 69,  8,  0, 71, 59, 66,\n","        72,  0, 74, 60, 63, 71,  0, 67, 56, 69, 54, 56, 60, 73, 56,  0, 64, 76,\n","         0, 57, 69, 60, 56, 65, 55, 95, 70,  0, 58, 66, 66, 55,  0, 70, 56, 65,\n","        70, 56,  8,  0, 64, 76,  0, 58, 66, 66, 55,  0, 57, 66, 69, 71, 72, 65,\n","        56,  0, 60, 65,  0, 57, 60, 65, 55, 60, 65, 58,  0, 70, 72, 54, 59,  0,\n","        52, 65,  0, 52, 55, 73, 60, 70, 56, 69,  0, 60, 65,  0, 70, 72, 54, 59,\n","         0, 52,  0, 71, 60, 64, 56,  0, 66, 57,  0, 65, 56, 56, 55,  8,  0, 52,\n","        65, 55,  0, 74, 59, 52, 71,  0, 71, 59, 66, 72,  0, 59, 52, 70, 71,  0,\n","        58, 52, 60, 65, 56, 55,  0, 60, 65,  0, 69, 56, 54, 56, 60, 73, 60, 65,\n","        58,  8,  0, 74, 60, 71, 59, 66, 72, 71,  0, 52, 55, 55])\n"]}],"source":["# let's now encode the entire text dataset and *store it into a torch.Tensor*\n","\n","data = torch.tensor(encode(text), dtype=torch.long)\n","print(data.shape, data.dtype)\n","print(data[:500]) # the 500 characters we looked at earier will to the GPT look like this"]},{"cell_type":"code","execution_count":null,"id":"fiscal-arkansas","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fiscal-arkansas","executionInfo":{"status":"ok","timestamp":1699370551090,"user_tz":360,"elapsed":5,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"6838eb06-0063-48de-e118-400de1a8f19a"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 8])\n","torch.Size([4, 8])\n"]}],"source":["# Let's now split up the data into train and validation sets\n","n = int(0.9*len(data)) # first 90% will be train, rest val\n","train_data = data[:n]\n","val_data = data[n:]\n","\n","block_size= 8\n","batch_size = 4\n","x_train, y_train = get_random_batch(split_type='train', block_size=8, batch_size = 4)\n","\n","print(x_train.shape)\n","print(y_train.shape)"]},{"cell_type":"code","execution_count":null,"id":"flush-conversion","metadata":{"id":"flush-conversion"},"outputs":[],"source":["class LayerNorm1d: # (used to be BatchNorm1d)\n","\n","  def __init__(self, dim, eps=1e-5, momentum=0.1):\n","    self.eps = eps\n","    self.gamma = torch.ones(dim)\n","    self.beta = torch.zeros(dim)\n","\n","  def __call__(self, x):\n","    # calculate the forward pass\n","    xmean = x.mean(1, keepdim=True) # batch mean\n","    xvar = x.var(1, keepdim=True) # batch variance\n","    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n","    self.out = self.gamma * xhat + self.beta\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.gamma, self.beta]\n"]},{"cell_type":"code","execution_count":null,"id":"revised-happening","metadata":{"id":"revised-happening"},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_random_batch(split, block_size = block_size, batch_size= batch_size)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear( n_embed, head_size, bias=False)\n","        self.query = nn.Linear( n_embed, head_size, bias=False)\n","        self.value = nn.Linear( n_embed, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x)   # (B,T,C)\n","        q = self.query(x) # (B,T,C)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,C)\n","        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(n_embed,  n_embed)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        proj = self.proj(out)\n","        out = self.dropout(proj)\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self,  n_embed):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear( n_embed, 4 *  n_embed),\n","            nn.ReLU(),\n","            nn.Linear(4 *  n_embed,  n_embed),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Transformer(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self,  n_embed, n_head):\n","        #  n_embed: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size =  n_embed // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward( n_embed)\n","        self.ln1 = nn.LayerNorm( n_embed)\n","        self.ln2 = nn.LayerNorm( n_embed)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","class BigramModel(nn.Module):\n","\n","    def __init__(self, char_vocab_size, n_embed):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(char_vocab_size,  n_embed)\n","        self.position_embedding_table = nn.Embedding(block_size,  n_embed)\n","        self.blocks = nn.Sequential(*[Transformer( n_embed, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm( n_embed) # final layer norm\n","        self.lm_head = nn.Linear( n_embed, char_vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","        x = tok_emb + pos_emb # (B,T,C)\n","        x = self.blocks(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T,char_vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            idx_cond = idx[:, -block_size:]\n","            # get the predictions\n","            logits, loss = self(idx_cond)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx"]},{"cell_type":"code","execution_count":32,"id":"baking-array","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"baking-array","outputId":"70446fdc-d4c1-49ce-e635-07d4b267f3dd","executionInfo":{"status":"error","timestamp":1699383720259,"user_tz":360,"elapsed":95019,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["201.823332 M parameters\n","step 0: train loss 4.7073, val loss 4.7111\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-1efd80ca396e>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# hyperparameters\n","import time\n","start_time = time.time()\n","\n","batch_size = 16 # how many independent sequences will we process in parallel?\n","block_size = 128 # what is the maximum context length for predictions?\n","max_iters = 5000\n","eval_interval = 100\n","learning_rate = 3e-4\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 10\n","n_embed = 512\n","n_head = 32\n","n_layer = 64\n","dropout = 0.2\n","# n_embed // n_head must equal batch_size\n","model = BigramModel(char_vocab_size, n_embed)\n","m = model.to(device)\n","\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","\n","optimizer = torch.optim.AdamW(m.parameters(), lr = learning_rate)\n","\n","for step in range(max_iters):\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if step % 200 == 0 or step == max_iters - 1:\n","        losses = estimate_loss()\n","        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    x_train, y_train = get_random_batch('train', block_size = block_size, batch_size= batch_size)\n","    #print(x_train)\n","    logits, loss = m(x_train, y_train)\n","    optimizer.zero_grad(set_to_none = 1)\n","    loss.backward()\n","    optimizer.step()\n","print(\"--- %s seconds ---\" % (time.time() - start_time))\n","print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long).to(device), max_new_tokens=1000)[0].tolist()))"]},{"cell_type":"code","execution_count":null,"id":"reduced-protection","metadata":{"id":"reduced-protection"},"outputs":[],"source":["torch.save(m, 'model.pth')"]},{"cell_type":"code","execution_count":null,"id":"pointed-soundtrack","metadata":{"id":"pointed-soundtrack"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ahead-battle","metadata":{"id":"ahead-battle"},"outputs":[],"source":["256//8"]},{"cell_type":"code","execution_count":null,"id":"ideal-italian","metadata":{"id":"ideal-italian"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}