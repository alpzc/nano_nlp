{"cells":[{"cell_type":"code","execution_count":4,"id":"bizarre-craps","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bizarre-craps","executionInfo":{"status":"ok","timestamp":1699417831013,"user_tz":360,"elapsed":33414,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"66071723-e060-4c57-aa4e-241260920d4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting traitlets==4.3.3\n","  Using cached traitlets-4.3.3-py2.py3-none-any.whl (75 kB)\n","Collecting ipython-genutils (from traitlets==4.3.3)\n","  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n","Collecting six (from traitlets==4.3.3)\n","  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n","Collecting decorator (from traitlets==4.3.3)\n","  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: ipython-genutils, six, decorator, traitlets\n","  Attempting uninstall: ipython-genutils\n","    Found existing installation: ipython-genutils 0.2.0\n","    Uninstalling ipython-genutils-0.2.0:\n","      Successfully uninstalled ipython-genutils-0.2.0\n","  Attempting uninstall: six\n","    Found existing installation: six 1.16.0\n","    Uninstalling six-1.16.0:\n","      Successfully uninstalled six-1.16.0\n","  Attempting uninstall: decorator\n","    Found existing installation: decorator 4.4.2\n","    Uninstalling decorator-4.4.2:\n","      Successfully uninstalled decorator-4.4.2\n","  Attempting uninstall: traitlets\n","    Found existing installation: traitlets 5.7.1\n","    Uninstalling traitlets-5.7.1:\n","      Successfully uninstalled traitlets-5.7.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","jupyter-core 5.5.0 requires traitlets>=5.3, but you have traitlets 4.3.3 which is incompatible.\n","jupyter-server 1.24.0 requires traitlets>=5.1, but you have traitlets 4.3.3 which is incompatible.\n","moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n","nbclient 0.8.0 requires traitlets>=5.4, but you have traitlets 4.3.3 which is incompatible.\n","nbconvert 6.5.4 requires traitlets>=5.0, but you have traitlets 4.3.3 which is incompatible.\n","nbformat 5.9.2 requires traitlets>=5.1, but you have traitlets 4.3.3 which is incompatible.\n","plotnine 0.12.3 requires numpy>=1.23.0, but you have numpy 1.21.6 which is incompatible.\n","tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.21.6 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed decorator-5.1.1 ipython-genutils-0.2.0 six-1.16.0 traitlets-4.3.3\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==228 (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==228\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mCollecting tiktoken\n","  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: tiktoken\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tiktoken-0.5.1\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.21.6)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.10/dist-packages (1.21.6)\n","\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m2.1.0+cu118\n","False\n"]}],"source":["!python -m pip install traitlets==4.3.3 --force-reinstall\n","!pip install pywin32==228\n","!pip install tiktoken\n","#installing past numpy version\n","!pip install gensim\n","!pip install numpy==1.21.6\n","\n","import torch\n","import tiktoken\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from gensim.models import Word2Vec\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.manifold import TSNE\n","from gensim.models import KeyedVectors\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(torch.__version__)\n","\n","print(torch.cuda.is_available())"]},{"cell_type":"code","execution_count":5,"id":"baking-attitude","metadata":{"id":"baking-attitude","executionInfo":{"status":"ok","timestamp":1699417831013,"user_tz":360,"elapsed":24,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["def get_batch(data, seq_len, i):\n","    \"\"\"Get a batch of data\n","    Parameters\n","    ----------\n","    data : torch.tensor\n","        The data to get the batch from\n","    seq_len : int\n","        The length of the sequence\n","    i : int\n","        The batch index\n","    Returns\n","    -------\n","    torch.tensor\n","        The input sequence\n","    torch.tensor\n","        The target sequence\n","    \"\"\"\n","    seq_len = min(seq_len, len(data) - 1 - i)\n","    inputs = data[i: i + seq_len]\n","    targets = data[i + 1: i + 1 + seq_len].reshape(-1)\n","    return inputs, targets\n","\n","def get_random_batch(split_type='train', block_size=8, batch_size = 4):\n","    \"\"\"Get a random batch of data\n","    Parameters\n","    ----------\n","    split_type : str, optional\n","        The split to get the batch from, by default 'train'\n","    block_size : int, optional\n","        The size of the block (quantity of words per example in the batch), by default 8\n","    batch_size : int, optional\n","        The batch size (quantity of examples in the batch), by default 4\n","    Returns\n","    -------\n","    torch.tensor\n","        The input sequence of size (batch_size, block_size)\n","    torch.tensor\n","        The target sequence of size (batch_size, block_size)\n","    \"\"\"\n","    data = train_data if split_type == 'train' else val_data\n","    ix = torch.randint(len(data) - block_size, (batch_size,))\n","    x = torch.stack([data[i:i+block_size] for i in ix])\n","    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","\n","    x, y = x.to(device), y.to(device)\n","\n","    return x, y\n","\n"]},{"cell_type":"code","execution_count":5,"id":"signed-american","metadata":{"id":"signed-american","executionInfo":{"status":"ok","timestamp":1699417831014,"user_tz":360,"elapsed":23,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"urban-promotion","metadata":{"id":"urban-promotion"},"source":["# TEXT IMPORT (can be changed later on)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETAsQEWNqh8m","executionInfo":{"status":"ok","timestamp":1699417832532,"user_tz":360,"elapsed":1540,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"0a78cc10-71a5-4e10-94f8-b07fec1a6aca"},"id":"ETAsQEWNqh8m","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":7,"id":"biblical-barbados","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"biblical-barbados","executionInfo":{"status":"ok","timestamp":1699417833012,"user_tz":360,"elapsed":488,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"6ffd2468-9bcf-40ea-d768-f65bc1d6d896"},"outputs":[{"output_type":"stream","name":"stdout","text":["sed by many more; for if you succeed in this you will have achieved no small success.” in profound silence i listened to what my friend said, and his observations made such an impression on me that, without attempting to question them, i admitted their soundness, and out of them i determined to make this preface; wherein, gentle reader, thou wilt perceive my friend’s good sense, my good fortune in finding such an adviser in such a time of need, and what thou hast gained in receiving, without addition or alteration, the story of the famous don quixote of la mancha, who is held by all the inhabitants of the district of the campo de montiel to have been the chastest lover and the bravest knight that has for many years been seen in that neighbourhood. i have no desire to magnify the service i render thee in making thee acquainted with so renowned and honoured a knight, but i do desire thy thanks for the acquaintance thou wilt make with the famous sancho panza, his squire, in whom, to my th\n"]}],"source":["with open('/content/drive/MyDrive/LLM TESTING/NanoGPT/data/don_quixote.txt', \"r\", encoding = 'utf-8') as f:\n","    text = f.read()\n","\n","text= text.replace('\\n', ' ').replace('  ', ' ')[121506:]\n","#text= text.replace(', ', ' , ').replace(': ', ' : ').replace('. ', ' . ').replace('; ', ' ; ').replace('? ', ' ? ').replace('! ', ' ! ')\n","#text = re.sub(r'(\\W|\\d)', r' \\1 ', text)\n","text = text.lower()\n","print(text[:1000])\n"]},{"cell_type":"code","execution_count":8,"id":"divine-custody","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"divine-custody","executionInfo":{"status":"ok","timestamp":1699417833628,"user_tz":360,"elapsed":286,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"cd080ef9-0fd1-40c7-e0b2-1648c59d028b"},"outputs":[{"output_type":"stream","name":"stdout","text":["['sed', ' ', 'by', ' ', 'many', ' ', 'more', ';', ' ', 'for', ' ', 'if', ' ', 'you', ' ', 'succeed', ' ', 'in', ' ', 'this', ' ', 'you', ' ', 'will', ' ', 'have', ' ', 'achieved', ' ', 'no', ' ', 'small', ' ', 'success', '.', '”', ' ', 'in', ' ', 'profound', ' ', 'silence', ' ', 'i', ' ', 'listened', ' ', 'to', ' ', 'what', ' ', 'my', ' ', 'friend', ' ', 'said', ',', ' ', 'and', ' ', 'his', ' ', 'observations', ' ', 'made', ' ', 'such', ' ', 'an', ' ', 'impression', ' ', 'on', ' ', 'me', ' ', 'that', ',', ' ', 'without', ' ', 'attempting', ' ', 'to', ' ', 'question', ' ', 'them', ',', ' ', 'i', ' ', 'admitted', ' ', 'their', ' ', 'soundness', ',', ' ', 'and']\n"]}],"source":["import re\n","\n","def split_into_words_special_chars_and_spaces(text):\n","    return re.findall('\\w+|\\S|\\s', text)\n","\n","text_separated = split_into_words_special_chars_and_spaces(text)\n","print(text_separated[:100])"]},{"cell_type":"code","execution_count":9,"id":"middle-injection","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"middle-injection","executionInfo":{"status":"ok","timestamp":1699417833629,"user_tz":360,"elapsed":8,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"b08ab1a2-a573-4bc0-93b4-a3349a15abdd"},"outputs":[{"output_type":"stream","name":"stdout","text":["['diviners', '84116', 'mischances', 'dozed', 'cupbearer', 'knowest', 'dying', 'communicating', 'souls', 'liege', 'hangers', 'incumbent', 'ávila', 'responded', 'scoldings', 'discloses', 'courtships', 'hard', 'pecked', 'weed', 'victims', 'liquor', '123k', 'erostratus', 'directions', '332k', 'hacked', 'projects', '_sù_', '249k', 'xix', 'bestows', 'fillies', 'instinct', 'principal', 'discarded', 'last', 'scrawl', 'overwhelmed', 'chamber', 'irons', 'verdant', 'dignitary', 'pillaged', 'charles', 'graze', 'unmannerly', 'average', 'thus', 'murdering', 'everlasting', 'killed', 'felled', 'biggest', 'displease', 'crying', 'peerless', '_par', 'firmest', 'pole', 'meant', 'avellaneda', 'seat', 'hassan', 'miracle', 'discord', 'fitter', 'bowshot', 'arch', 'pobre', 'martial', 'incurring', 'wishing', 'absolves', 'mines', 'heaths', 'rubies', 'ignoramus', 'stamps', 'ham', 'itself', 'quinces', 'tunis', 'muttering', 'cancel', 'slacken', 'fulfilling', 'connection', 'noised', 'needles', 'trifle', 'polo', 'perdicis', 'address', 'fanciest', 'pillars', 'obedient', 'logiquous', 'during', 'bottle']\n","VOC LENGTH:  15520\n"]}],"source":["vocabulary = list(set(text_separated))\n","print(vocabulary[0:100])\n","print(\"VOC LENGTH: \", len(vocabulary))"]},{"cell_type":"code","execution_count":10,"id":"minus-people","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"minus-people","executionInfo":{"status":"ok","timestamp":1699417833629,"user_tz":360,"elapsed":5,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"6bc042a4-d30f-424b-f812-9fdf38b70b99"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{' ', ';', 'by', 'for', 'many', 'more', 'sed'}"]},"metadata":{},"execution_count":10}],"source":["set(text_separated[:10])"]},{"cell_type":"code","execution_count":11,"id":"sweet-nature","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sweet-nature","executionInfo":{"status":"ok","timestamp":1699417833943,"user_tz":360,"elapsed":14,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"d2b3160a-02fc-4f5f-b448-3a85d3bc1b8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Chracters on .txt file:  2190617\n","Words on .txt file:  410699\n","Unique characters:  70\n","Unique words:  15520\n"]}],"source":["print('Chracters on .txt file: ', len(text))\n","print('Words on .txt file: ', len(text.split(' ')))\n","\n","\n","chars = sorted(list(set(text)))\n","char_vocab_size = len(chars)\n","\n","words_vocab_size = len(vocabulary)\n","\n","print('Unique characters: ', char_vocab_size)\n","print('Unique words: ', words_vocab_size)\n"]},{"cell_type":"markdown","id":"compound-phase","metadata":{"id":"compound-phase"},"source":["# TRAINING DATA PREPARATION"]},{"cell_type":"markdown","id":"incoming-irrigation","metadata":{"id":"incoming-irrigation"},"source":["## NORMAL TOKENIZATION"]},{"cell_type":"code","execution_count":12,"id":"empty-remark","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"empty-remark","executionInfo":{"status":"ok","timestamp":1699417833943,"user_tz":360,"elapsed":5,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"2f3241c2-bba5-4ee7-e4b9-ab2d6472639d"},"outputs":[{"output_type":"stream","name":"stdout","text":["[15282, 7334, 1699, 7334, 360, 7334, 1841, 10489, 7334, 11286, 7334, 5517, 7334, 14877, 7334, 12574, 7334, 2084, 7334, 6415, 7334, 14877, 7334, 2213, 7334, 6611, 7334, 11350, 7334, 13164, 7334, 8803, 7334, 521, 7029, 3984, 7334, 2084, 7334, 3888, 7334, 1606, 7334, 10234, 7334, 4898, 7334, 10886, 7334, 8699, 7334, 2797, 7334, 13833, 7334, 9679, 1112, 7334, 5179, 7334, 2737, 7334, 10752, 7334, 6357, 7334, 6720, 7334, 8633, 7334, 15211, 7334, 12152, 7334, 15503, 7334, 14673, 1112, 7334]\n","sed by many more; for if you succeed in this you will have achieved no small success.” in profound silence i listened to what my friend said, and his observations made such an impression on me that, \n"]}],"source":["# For now, we will be using a basic encoding using only individual characters\n","\n","stoi = { ch:i for i,ch in enumerate(vocabulary) }\n","itos = { i:ch for i,ch in enumerate(vocabulary) }\n","\n","def encode(text_string):\n","    sep_text =split_into_words_special_chars_and_spaces(text_string)\n","    return [stoi[i] for i in sep_text]\n","\n","def decode(encoded_text_list):\n","    decoded_text = [itos[i] for i in encoded_text_list]\n","    return ''.join(decoded_text)\n","\n","\n","print(encode(text[0:199]))\n","print(decode(encode(text[0:199])))\n","\n"]},{"cell_type":"markdown","id":"stuck-macedonia","metadata":{"id":"stuck-macedonia"},"source":["## (NOT WORKING YET) TOKENIZATION: Using TikToken For Tokenization (can be changed later on to other like SentencePiece)\n","Tiktoken does tokenization per word and special character."]},{"cell_type":"code","execution_count":13,"id":"naval-identity","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"naval-identity","executionInfo":{"status":"ok","timestamp":1699417836961,"user_tz":360,"elapsed":3021,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"2a001648-73ec-4147-c44d-8acabcd101a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["544408\n","410699\n","UNIQUE TOKENS:  12714\n"]}],"source":["enc = tiktoken.get_encoding('gpt2')\n","\n","tokenized_text = enc.encode(text)\n","print(len(tokenized_text))\n","\n","print(len(text.split(' ')))\n","\n","token_voc_size = len(list(set(tokenized_text)))\n","print('UNIQUE TOKENS: ',token_voc_size )"]},{"cell_type":"code","execution_count":14,"id":"special-vatican","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"special-vatican","executionInfo":{"status":"ok","timestamp":1699417836963,"user_tz":360,"elapsed":31,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"786cdcf0-aa32-46ea-c266-5fafec11dd57"},"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded text:  [36622, 416, 867, 517, 26, 329, 611, 345, 6758, 287, 428, 345, 481, 423, 8793, 645, 1402, 1943, 13, 447, 251, 287, 11982, 9550, 1312, 16399, 284, 644, 616, 1545, 531, 11, 290, 465, 13050, 925, 884, 281, 10647, 319, 502, 326, 11, 1231, 9361, 284, 1808, 606, 11, 1312, 6848, 511, 2128, 1108, 11, 290, 503, 286, 606, 1312, 5295, 284, 787, 428, 662, 2550, 26, 22881, 11, 10296, 9173, 11, 14210, 266, 2326, 19973, 616, 1545, 447, 247, 82, 922, 2565, 11, 616, 922, 15807, 287, 4917, 884, 281, 12534, 287, 884, 257, 640, 286, 761, 11, 290]\n","Decoded text:  sed by many more; for if you succeed in this you will have achieved no small success.” in profound silence i listened to what my friend said, and his observations made such an impression on me that, without attempting to question them, i admitted their soundness, and out of them i determined to make this preface; wherein, gentle reader, thou wilt perceive my friend’s good sense, my good fortune in finding such an adviser in such a time of need, and\n"]}],"source":["data = torch.tensor(tokenized_text, dtype=torch.long)\n","\n","print('Encoded text: ', tokenized_text[:100])\n","print('Decoded text: ', enc.decode(tokenized_text[:100]))"]},{"cell_type":"code","execution_count":14,"id":"revolutionary-demographic","metadata":{"id":"revolutionary-demographic","executionInfo":{"status":"ok","timestamp":1699417836964,"user_tz":360,"elapsed":16,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":[]},{"cell_type":"markdown","id":"faced-appearance","metadata":{"id":"faced-appearance"},"source":["## (NOT WORKING YET) EMBEDDING: Implementing Word2Vec Embeddings (can be changed later on like GloVe)\n","In this case, the embedding imported transforms each word and special character into a 300-dim vector, meaning that a sentence of 8 words will be transformed into a [8, 300] tensor."]},{"cell_type":"code","execution_count":15,"id":"congressional-muscle","metadata":{"id":"congressional-muscle","executionInfo":{"status":"ok","timestamp":1699417916602,"user_tz":360,"elapsed":79652,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["emb_model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/LLM TESTING/NanoGPT/embedding_models/GoogleNews-vectors-negative300.bin', binary=True)"]},{"cell_type":"code","execution_count":16,"id":"governing-montana","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"governing-montana","executionInfo":{"status":"ok","timestamp":1699417918559,"user_tz":360,"elapsed":2014,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"6933f0ae-58c0-48f3-87ba-95b4be16eb6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(294514, 300)\n","Unique words (vocab size):  29945\n"]}],"source":["#using the model to get embeddings of our text\n","embeddings = []\n","for word in text.split(' '):\n","    try:\n","        embeddings.append(emb_model[word])\n","    except:\n","        pass\n","\n","embeddings = np.array(embeddings)\n","print(embeddings.shape)\n","\n","words_vocab_size = len(list(set( text.split(' '))))\n","print(\"Unique words (vocab size): \", words_vocab_size)"]},{"cell_type":"code","execution_count":17,"id":"wrapped-oliver","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wrapped-oliver","executionInfo":{"status":"ok","timestamp":1699417918559,"user_tz":360,"elapsed":6,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"f740a6d0-c99c-4777-f9c4-43d49963c5b1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Word:  mancha,\n","Embedding:  [ 0.0703125   0.08691406  0.08789062  0.0625      0.06933594 -0.10888672\n"," -0.08154297 -0.15429688  0.02075195  0.13183594 -0.11376953 -0.03735352\n","  0.06933594  0.078125   -0.10302734 -0.09765625  0.04418945  0.10253906\n"," -0.06079102 -0.03613281 -0.04541016  0.04736328 -0.12060547 -0.06396484\n","  0.0022583   0.03710938 -0.00291443  0.11767578  0.06176758  0.06396484\n","  0.08105469 -0.06884766 -0.0213623   0.05517578 -0.08544922  0.06884766\n"," -0.12792969 -0.03320312  0.09863281  0.17578125  0.11083984 -0.03466797\n"," -0.04711914 -0.00848389  0.03588867  0.10302734  0.02697754 -0.02868652\n"," -0.00512695  0.10644531  0.05981445  0.09423828  0.03369141 -0.02709961\n"," -0.09423828  0.00102997 -0.04833984  0.03442383  0.08105469 -0.11328125\n"," -0.08886719  0.03588867 -0.14550781 -0.24414062 -0.06152344  0.05297852\n","  0.05688477  0.1796875   0.06103516  0.08691406  0.12402344 -0.0402832\n","  0.02258301  0.17773438 -0.02966309 -0.02966309  0.1171875   0.03112793\n"," -0.09619141  0.06640625  0.00469971 -0.08007812  0.06298828 -0.02062988\n"," -0.0546875  -0.13574219 -0.06347656  0.08349609 -0.06396484  0.02148438\n","  0.07714844 -0.03710938 -0.03369141 -0.18359375 -0.07275391  0.01586914\n","  0.09326172 -0.06152344 -0.01422119 -0.00344849  0.0111084  -0.15820312\n"," -0.01708984  0.00619507 -0.00872803 -0.08056641 -0.01525879 -0.08789062\n","  0.003479   -0.01611328 -0.0123291   0.09765625 -0.13964844 -0.0859375\n"," -0.02685547  0.05395508  0.1328125   0.11279297  0.12109375  0.08544922\n"," -0.0071106   0.04467773 -0.14550781 -0.00320435 -0.11767578 -0.06542969\n","  0.07128906 -0.09423828 -0.03027344  0.12011719  0.08007812 -0.09472656\n"," -0.16210938 -0.07763672  0.02124023 -0.08154297  0.00393677 -0.15722656\n"," -0.09814453  0.03979492  0.03930664 -0.00909424  0.10302734  0.06787109\n"," -0.04272461  0.06347656 -0.04907227  0.02087402 -0.16699219  0.09326172\n","  0.09375     0.00686646  0.05371094  0.05249023 -0.02441406 -0.0324707\n"," -0.06152344 -0.0055542   0.09619141  0.0378418   0.01220703 -0.04394531\n"," -0.00747681  0.10546875  0.02038574  0.14550781  0.08203125  0.00576782\n","  0.00457764 -0.09277344 -0.13867188 -0.05737305 -0.05151367 -0.13085938\n"," -0.13964844 -0.02050781 -0.02709961  0.03271484  0.10498047 -0.00233459\n"," -0.02258301  0.00050354 -0.11083984  0.08496094 -0.12988281 -0.01745605\n"," -0.00035858  0.10791016  0.08886719  0.04467773  0.02514648  0.02380371\n","  0.08105469  0.02368164 -0.10986328  0.00537109 -0.0177002  -0.03393555\n"," -0.03295898 -0.1640625   0.09570312 -0.01831055  0.00531006 -0.03442383\n"," -0.04418945 -0.06640625 -0.01794434 -0.02966309 -0.00759888 -0.05126953\n"," -0.05419922  0.08935547 -0.07177734  0.01525879 -0.08251953 -0.03173828\n","  0.03564453 -0.02124023 -0.05932617 -0.01306152  0.046875    0.02307129\n","  0.02099609 -0.07861328 -0.00805664  0.01953125 -0.0055542   0.04150391\n","  0.02783203  0.01361084  0.03466797 -0.18261719  0.12011719  0.07421875\n"," -0.04101562 -0.00994873  0.04296875 -0.0072937   0.12304688  0.05761719\n"," -0.0534668  -0.03222656 -0.00909424 -0.04663086  0.04394531 -0.05078125\n","  0.06884766  0.00299072 -0.00418091 -0.04418945  0.07373047 -0.01275635\n","  0.06738281  0.00628662  0.07519531 -0.0378418   0.00488281  0.04467773\n"," -0.06738281  0.00970459  0.00473022  0.02050781  0.07128906  0.17089844\n","  0.17382812  0.05566406  0.09130859 -0.03735352  0.04980469 -0.03930664\n","  0.04418945  0.0625      0.04858398 -0.05322266  0.04882812 -0.13085938\n"," -0.02893066 -0.03613281 -0.06079102 -0.05737305  0.12304688 -0.08251953\n"," -0.01190186  0.125       0.00135803  0.06396484 -0.10644531 -0.14355469\n"," -0.04223633  0.02404785 -0.16894531 -0.08886719 -0.08056641  0.06494141\n","  0.0612793  -0.04736328 -0.05883789 -0.04760742  0.01446533 -0.0625    ]\n"]}],"source":["#printing an example of the embedding\n","print('Word: ', text.split(' ')[100])\n","print('Embedding: ', embeddings[100])"]},{"cell_type":"code","execution_count":18,"id":"angry-terror","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"angry-terror","executionInfo":{"status":"ok","timestamp":1699417942687,"user_tz":360,"elapsed":24132,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"2634e456-81d9-4078-b309-491a8620d145"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reducing dimensionality...\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7daf72b97520>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 847, in match_library_callback\n","    self._make_controller_from_path(filepath)\n","  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 984, in _make_controller_from_path\n","    lib_controller = controller_class(filepath=filepath, prefix=prefix)\n","  File \"/usr/local/lib/python3.10/dist-packages/threadpoolctl.py\", line 111, in __init__\n","    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n","  File \"/usr/lib/python3.10/ctypes/__init__.py\", line 374, in __init__\n","    self._handle = _dlopen(self._name, mode)\n","OSError: /usr/local/lib/python3.10/dist-packages/numpy.libs/libopenblas64_p-r0-742d56dc.3.20.so: cannot open shared object file: No such file or directory\n"]},{"output_type":"stream","name":"stdout","text":["Done!\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["#using TSNE to reduce the dimensionality of the embeddings for just some words\n","print('Reducing dimensionality...')\n","tsne = TSNE(n_components=2)\n","embeddings_2d = tsne.fit_transform(embeddings[:2500])\n","print('Done!')\n","\n","#plotting the embeddings using matplotlib\n","plt.figure(figsize=(10, 10))\n","plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=1)\n","plt.show()"]},{"cell_type":"markdown","id":"palestinian-order","metadata":{"id":"palestinian-order"},"source":["## TRAINING OWN EMBEDDING"]},{"cell_type":"code","execution_count":19,"id":"pleased-reservoir","metadata":{"id":"pleased-reservoir","executionInfo":{"status":"ok","timestamp":1699417943419,"user_tz":360,"elapsed":743,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import time\n","\n","from gensim.models import Word2Vec\n"]},{"cell_type":"code","execution_count":20,"id":"composed-vaccine","metadata":{"id":"composed-vaccine","executionInfo":{"status":"ok","timestamp":1699417943582,"user_tz":360,"elapsed":169,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["sentences = []\n","start = 0\n","for i, word in enumerate(text_separated):\n","    if word in [\".\", '?', '!']:\n","        sentences.append(text_separated[start : i+1])\n","        start = i+1\n"]},{"cell_type":"code","execution_count":21,"id":"corresponding-links","metadata":{"id":"corresponding-links","executionInfo":{"status":"ok","timestamp":1699417972565,"user_tz":360,"elapsed":28987,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["train_emb_sentences =  [item for item in sentences for _ in range(2)]\n","\n","emb_model = Word2Vec(sentences=sentences,\n","                 min_count=1,\n","                 sg=1,\n","                 vector_size =500,\n","                 workers=4)\n"]},{"cell_type":"code","execution_count":22,"id":"intensive-little","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"intensive-little","executionInfo":{"status":"ok","timestamp":1699417972565,"user_tz":360,"elapsed":56,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"6533e68c-d838-45dc-d4eb-a89a5839191c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('another', 0.6823879480361938),\n"," ('poor', 0.6515121459960938),\n"," ('man', 0.6266782283782959),\n"," ('old', 0.6166909337043762),\n"," ('an', 0.6100119352340698),\n"," ('rich', 0.6052917242050171),\n"," ('some', 0.6019343733787537),\n"," ('young', 0.6000994443893433),\n"," ('low', 0.5943751335144043),\n"," ('dead', 0.5917929410934448)]"]},"metadata":{},"execution_count":22}],"source":["emb_model.wv.most_similar('a')"]},{"cell_type":"markdown","id":"hourly-attraction","metadata":{"id":"hourly-attraction"},"source":["# MODEL: Making a Basic Bigram Model\n","Bigram models are the simplest form of language models that assigns probabilities to word sequences. It is based on the assumption that the probability of a word depends only on the previous word. In other words, it assumes that the probability of a word depends only on the previous word. The probability of a word depends on the previous two words in the case of a trigram model. The probability of a word depends on the previous n words in the case of an n-gram model.\n","\n","This simple model is just a random model that generates the next character based on the last character (not even the last n-characters). *Tokens DO NOT talk to each other*."]},{"cell_type":"code","execution_count":23,"id":"acting-auditor","metadata":{"id":"acting-auditor","executionInfo":{"status":"ok","timestamp":1699417972566,"user_tz":360,"elapsed":51,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["class LayerNorm1d: # (used to be BatchNorm1d)\n","\n","  def __init__(self, dim, eps=1e-5, momentum=0.1):\n","    self.eps = eps\n","    self.gamma = torch.ones(dim)\n","    self.beta = torch.zeros(dim)\n","\n","  def __call__(self, x):\n","    # calculate the forward pass\n","    xmean = x.mean(1, keepdim=True) # batch mean\n","    xvar = x.var(1, keepdim=True) # batch variance\n","    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n","    self.out = self.gamma * xhat + self.beta\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.gamma, self.beta]\n"]},{"cell_type":"code","execution_count":24,"id":"genetic-entrepreneur","metadata":{"id":"genetic-entrepreneur","executionInfo":{"status":"ok","timestamp":1699417973501,"user_tz":360,"elapsed":985,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_random_batch(split, block_size = block_size, batch_size= batch_size)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear( n_embed, head_size, bias=False)\n","        self.query = nn.Linear( n_embed, head_size, bias=False)\n","        self.value = nn.Linear( n_embed, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x)   # (B,T,C)\n","        q = self.query(x) # (B,T,C)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,C)\n","        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(n_embed,  n_embed)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        proj = self.proj(out)\n","        out = self.dropout(proj)\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self,  n_embed):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear( n_embed, 4 *  n_embed),\n","            nn.ReLU(),\n","            nn.Linear(4 *  n_embed,  n_embed),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Transformer(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self,  n_embed, n_head):\n","        #  n_embed: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size =  n_embed // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward( n_embed)\n","        self.ln1 = nn.LayerNorm( n_embed)\n","        self.ln2 = nn.LayerNorm( n_embed)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","class BigramModel(nn.Module):\n","\n","    def __init__(self, char_vocab_size, n_embed):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(char_vocab_size,  n_embed)\n","        self.position_embedding_table = nn.Embedding(block_size,  n_embed)\n","        self.blocks = nn.Sequential(*[Transformer( n_embed, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm( n_embed) # final layer norm\n","        self.lm_head = nn.Linear( n_embed, char_vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","        x = tok_emb + pos_emb # (B,T,C)\n","        x = self.blocks(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T,char_vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            idx_cond = idx[:, -block_size:]\n","            # get the predictions\n","            logits, loss = self(idx_cond)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx"]},{"cell_type":"code","execution_count":25,"id":"productive-reference","metadata":{"id":"productive-reference","executionInfo":{"status":"ok","timestamp":1699417973502,"user_tz":360,"elapsed":21,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_random_batch(split, block_size = block_size, batch_size= batch_size)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear( n_embed, head_size, bias=False)\n","        self.query = nn.Linear( n_embed, head_size, bias=False)\n","        self.value = nn.Linear( n_embed, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x)   # (B,T,C)\n","        q = self.query(x) # (B,T,C)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,C)\n","        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(n_embed,  n_embed)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        proj = self.proj(out)\n","        out = self.dropout(proj)\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self,  n_embed):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear( n_embed, 4 *  n_embed),\n","            nn.ReLU(),\n","            nn.Linear(4 *  n_embed,  n_embed),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Transformer(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self,  n_embed, n_head):\n","        #  n_embed: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size =  n_embed // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward( n_embed)\n","        self.ln1 = nn.LayerNorm( n_embed)\n","        self.ln2 = nn.LayerNorm( n_embed)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","class BigramModel(nn.Module):\n","\n","    def __init__(self, char_vocab_size, n_embed):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(char_vocab_size,  n_embed)\n","        self.position_embedding_table = nn.Embedding(block_size,  n_embed)\n","        self.blocks = nn.Sequential(*[Transformer( n_embed, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm( n_embed) # final layer norm\n","        self.lm_head = nn.Linear( n_embed, char_vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","        x = tok_emb + pos_emb # (B,T,C)\n","        x = self.blocks(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T,char_vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            idx_cond = idx[:, -block_size:]\n","            # get the predictions\n","            logits, loss = self(idx_cond)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx"]},{"cell_type":"code","execution_count":26,"id":"periodic-young","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":140},"id":"periodic-young","executionInfo":{"status":"error","timestamp":1699417973503,"user_tz":360,"elapsed":21,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}},"outputId":"7db3ed8a-8336-4d1d-ecbc-0e1ad59f0af7"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-27dfd9dffb00>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    model = BigramModel(token_voc_size, n_embed) word2vec_model, vocab_size, n_embed):\u001b[0m\n\u001b[0m                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"]}],"source":["# hyperparameters\n","batch_size = 64 # how many independent sequences will we process in parallel?\n","block_size = 256 # what is the maximum context length for predictions?\n","max_iters = 5000\n","eval_interval = 100\n","learning_rate = 3e-4\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 200\n","n_embed = 384\n","n_head = 6\n","n_layer = 6\n","dropout = 0.2\n","# n_embed // n_head must equal batch_size\n","model = BigramModel(token_voc_size, n_embed) word2vec_model, vocab_size, n_embed):\n","m = model.to(device)\n","\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","\n","optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)\n","\n","for step in range(max_iters):\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if step % 200 == 0 or step == max_iters - 1:\n","        losses = estimate_loss()\n","        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","\n","    x_train, y_train = get_random_batch('train', block_size = block_size, batch_size= batch_size)\n","    #print(x_train)\n","    logits, loss = m(x_train, y_train)\n","    optimizer.zero_grad(set_to_none = 1)\n","    loss.backward()\n","    optimizer.step()\n","\n","\n","print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long).to(device), max_new_tokens=1000)[0].tolist()))"]},{"cell_type":"code","execution_count":null,"id":"massive-injection","metadata":{"id":"massive-injection","executionInfo":{"status":"aborted","timestamp":1699417973504,"user_tz":360,"elapsed":18,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["torch.save(m, 'model.pth')"]},{"cell_type":"markdown","id":"paperback-belarus","metadata":{"id":"paperback-belarus"},"source":["## EMBEDDING WORD BY WORD TESTING"]},{"cell_type":"code","execution_count":27,"id":"transparent-sweden","metadata":{"id":"transparent-sweden","executionInfo":{"status":"ok","timestamp":1699418193315,"user_tz":360,"elapsed":199,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","            X, Y = get_random_batch(split, block_size = block_size, batch_size= batch_size)\n","            logits, loss = model(X, Y)\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear( n_embed, head_size, bias=False)\n","        self.query = nn.Linear( n_embed, head_size, bias=False)\n","        self.value = nn.Linear( n_embed, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        B,T,C = x.shape\n","        k = self.key(x)   # (B,T,C)\n","        q = self.query(x) # (B,T,C)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,C)\n","        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n","        return out\n","\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(n_embed,  n_embed)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1)\n","        proj = self.proj(out)\n","        out = self.dropout(proj)\n","        return out\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self,  n_embed):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear( n_embed, 4 *  n_embed),\n","            nn.ReLU(),\n","            nn.Linear(4 *  n_embed,  n_embed),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Transformer(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self,  n_embed, n_head):\n","        #  n_embed: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size =  n_embed // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward( n_embed)\n","        self.ln1 = nn.LayerNorm( n_embed)\n","        self.ln2 = nn.LayerNorm( n_embed)\n","\n","    def forward(self, x):\n","        x = x + self.sa(self.ln1(x))\n","        x = x + self.ffwd(self.ln2(x))\n","        return x\n","\n","class BigramModel(nn.Module):\n","\n","    def __init__(self, char_vocab_size, n_embed):\n","        super().__init__()\n","        # each token directly reads off the logits for the next token from a lookup table\n","        self.token_embedding_table = nn.Embedding(char_vocab_size,  n_embed)\n","        self.position_embedding_table = nn.Embedding(block_size,  n_embed)\n","        self.blocks = nn.Sequential(*[Transformer( n_embed, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm( n_embed) # final layer norm\n","        self.lm_head = nn.Linear( n_embed, char_vocab_size)\n","\n","    def forward(self, idx, targets=None):\n","        B, T = idx.shape\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","        x = tok_emb + pos_emb # (B,T,C)\n","        x = self.blocks(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T,char_vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, idx, max_new_tokens):\n","        # idx is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            idx_cond = idx[:, -block_size:]\n","            # get the predictions\n","            logits, loss = self(idx_cond)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n","        return idx"]},{"cell_type":"code","execution_count":null,"id":"enhanced-beverage","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enhanced-beverage","outputId":"825ed96c-4bb1-4d22-d94a-65393b436bbd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model Defined\n","116.801696 M parameters\n","step 0: train loss 9.9520, val loss 9.9426\n"]}],"source":["# hyperparameters\n","data  = torch.tensor(encode(text), dtype=torch.long)\n","batch_size = 16 # how many independent sequences will we process in parallel?\n","block_size = 128 # what is the maximum context length for predictions?\n","max_iters = 5000\n","eval_interval = 100\n","learning_rate = 3e-4\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 20\n","n_embed = 512\n","n_head = 32\n","n_layer = 32\n","dropout = 0.2\n","vocab_size = len(vocabulary)\n","epoch_list = []\n","train_loss = []\n","val_loss = []\n","# n_embed // n_head must equal batch_size\n","\n","#defining model\n","import os.path\n","if os.path.exists('/content/drive/MyDrive/LLM TESTING/NanoGPT/model_backup.pth'):\n","    model = torch.load('/content/drive/MyDrive/LLM TESTING/NanoGPT/model_backup.pth')\n","else:\n","    model = BigramModel(vocab_size, n_embed)\n","m = model.to(device)\n","print('Model Defined')\n","\n","# Setting the training split to 90%\n","train_split = int(0.9 * len(data))\n","train_data = data[:train_split]\n","val_data = data[train_split:]\n","\n","print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n","\n","\n","optimizer = torch.optim.AdamW(m.parameters(), lr =learning_rate)\n","\n","for step in range(max_iters):\n","\n","    # every once in a while evaluate the loss on train and val sets\n","    if step % eval_interval == 0 or step == max_iters - 1:\n","        epoch_list.append(step)\n","        losses = estimate_loss()\n","        train_loss.append(losses['train'])\n","        val_loss.append(losses['val'])\n","        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n","        torch.save(m, 'model_backup.pth')\n","\n","\n","    x_train, y_train = get_random_batch('train', block_size = block_size, batch_size= batch_size)\n","    #print(x_train)\n","    logits, loss = m(x_train, y_train)\n","    optimizer.zero_grad(set_to_none = 1)\n","    loss.backward()\n","    optimizer.step()\n","\n","import matplotlib.pyplot as plt\n","plt.figure()\n","plt.plot(epoch_list, train_loss)\n","plt.plot(epoch_list, val_loss)\n","plt.show()\n","\n","print(decode(m.generate(idx =torch.zeros((1, 1), dtype=torch.long).to(device), max_new_tokens=1000)[0].tolist()))"]},{"cell_type":"code","execution_count":null,"id":"located-notice","metadata":{"id":"located-notice"},"outputs":[],"source":["torch.save(m, 'model.pth')"]},{"cell_type":"code","execution_count":null,"id":"maritime-drawing","metadata":{"id":"maritime-drawing","executionInfo":{"status":"aborted","timestamp":1699417973506,"user_tz":360,"elapsed":17,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["encoded = list(enc.encode('I am Testing this tokenization model.'))\n","print(encoded)\n","print([enc.decode([i]) for i in encoded])\n","print([emb_model[str] for str in [enc.decode([i]) for i in encoded]])\n","\n","# get wmbeddings of these\n",""]},{"cell_type":"code","execution_count":null,"id":"pharmaceutical-chair","metadata":{"id":"pharmaceutical-chair","executionInfo":{"status":"aborted","timestamp":1699417973508,"user_tz":360,"elapsed":176067,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"changed-implementation","metadata":{"id":"changed-implementation","executionInfo":{"status":"aborted","timestamp":1699417973509,"user_tz":360,"elapsed":176065,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["model = Word2Vec(text) #traain using the direct translations from tokenized to list of strings!\n","model\n","\n","#NEED TO MAKE EMBEDDINGS FOR EACH TOKENIZATION TRANSLATION (ORIGIN OF ERROR ABOVE)\n","# 1. separate original string text into sentences\n","# 2. for each sentence, run tokenization\n","# 3. for each tokenized sentence, do the same as in print([emb_model[str] for str in [enc.decode([i]) for i in encoded]]) above\n","# 4. With the list of sentences as [[], [], []], feed into Word2Vec(sentences)\n","# 5. Save model\n","# 6. Load as done before in the code and retest cell above\n","\n","# https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n","\n","#OPTION 2: FINETUNE MODEL DOWNLOADED"]},{"cell_type":"code","execution_count":null,"id":"korean-prior","metadata":{"id":"korean-prior","executionInfo":{"status":"aborted","timestamp":1699417973510,"user_tz":360,"elapsed":176063,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["len(text_separated)"]},{"cell_type":"code","execution_count":null,"id":"technical-fabric","metadata":{"id":"technical-fabric","executionInfo":{"status":"aborted","timestamp":1699417973510,"user_tz":360,"elapsed":176060,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":["encode(text_separated)\n"]},{"cell_type":"code","execution_count":null,"id":"introductory-consensus","metadata":{"id":"introductory-consensus","executionInfo":{"status":"aborted","timestamp":1699417973515,"user_tz":360,"elapsed":176061,"user":{"displayName":"Álvaro López","userId":"12535611900818212285"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.2"},"toc-autonumbering":true,"toc-showmarkdowntxt":false,"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}